{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = []\n",
    "\n",
    "# directory =  r\"G:\\ML_Datasets\\IS460_proj\\maestro-v3.0.0\"  #Set your directory here, add r in fron if need to convert to raw string\n",
    "directory =  r\"/mnt/g/ML_Datasets/IS460_proj/maestro-v3.0.0\"\n",
    "# directory = r\"G:\\ML_Datasets\\IS460_proj\\maps\\ENSTDkCl\"\n",
    "#directory = #r\"G:\\ML_Datasets\\IS460_proj\\maps\\AkPnBcht\"\n",
    "#directory = r\"G:\\ML_Datasets\\IS460_proj\\maps\\AkPnBcht\\AkPnBcht\\ISOL\"\n",
    "\n",
    "osdirectory = fr\"{directory}\"\n",
    "\n",
    "for root, dirs, files in os.walk(os.path.abspath(osdirectory)):\n",
    "    for file in files:\n",
    "        if file[-4:] != \"midi\":   #Skipping any .txt files, as we only wish to work with MIDI and wav\n",
    "            filelist.append((os.path.join(root, file), file, root))      \n",
    "\n",
    "\n",
    "# filelist = filelist[1276:1914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/mnt/g/ML_Datasets/IS460_proj/maestro-v3.0.0/2004/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav.txt',\n",
       " 'MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav.txt',\n",
       " '/mnt/g/ML_Datasets/IS460_proj/maestro-v3.0.0/2004')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\ML_Datasets\\\\IS460_proj\\\\maestro-v3.0.0\\\\2013\\\\ORIG-MIDI_02_7_7_13_Group__MID--AUDIO_19_R1_2013_wav--1.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filelist[132*2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfile = open(filelist[132*2+1][0], \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "hop_len = 512\n",
    "# n_bins_in = 252\n",
    "# bins_octaves_in = 36\n",
    "# win_step = 0.01\n",
    "no_notes = 88\n",
    "# num_cep_def = 40\n",
    "# num_filt_def = 40\n",
    "# length_per_file = 4000000\n",
    "data_frame_size = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [44:25<00:00,  8.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"File Name\",     #Create column headers for PD df\n",
    "                             \"Subset Number\",\n",
    "                             \"Sampling Rate\", \n",
    "                             \"Class\",\n",
    "                             \"Midi Labels\",\n",
    "                             \"Wav Array\", \n",
    "                             \"Status\"])\n",
    "\n",
    "\n",
    "for file in tqdm(range(0,int(len(filelist)), 2)):\n",
    "    # print(file)\n",
    "    try: \n",
    "        # print(file+1)\n",
    "        txtfile_path = filelist[file][0]\n",
    "        wavfile_path = filelist[file+1][0]\n",
    "        \n",
    "        # print(txtfile_path, wavfile_path)\n",
    "        wavsig, wavrate = librosa.load(path = wavfile_path, mono=True,  dtype=np.float32)\n",
    "        # print(\"wavsig, wavrate\")\n",
    "        melspecgram = librosa.feature.melspectrogram(y=wavsig, sr= wavrate, n_mels = 128, hop_length = hop_len, n_fft = 2048)\n",
    "        # print(melspecgram)\n",
    "        melspecgram = ((librosa.power_to_db(melspecgram, ref=np.max)+80)/80).transpose()\n",
    "        # print(\"melspecgram\")\n",
    "        \n",
    "\n",
    "        win_len = hop_len/float(wavrate) # hop_len = 512 default, hop_len, win_length is how much time is inbetween each frame\n",
    "\n",
    "        no_frames = melspecgram.shape[0] # 1 frames is 1 timestep in the melspectrogram\n",
    "        labels = np.zeros((no_frames, no_notes)) # empty array to be filled in later\n",
    "        timing_arr = np.arange(1, no_frames + 1) * win_len # creates a 1D array where each element is (i+1)*win_length\n",
    "\n",
    "        # print(txtfile_path)\n",
    "        txtfile = open(txtfile_path, \"r\") # open txt file to check for onset and offset of keys\n",
    "        for line in txtfile:\n",
    "            line_split = line.strip().split() # line is split, if it has timing, it will be split into (onsettime, offsettime, key)\n",
    "            if line_split == []: # condition that helps to skip blank lines\n",
    "                continue\n",
    "                \n",
    "            if line_split[0] != \"OnsetTime\":\n",
    "                # print(txtfile_path)\n",
    "                # print(\"time\")\n",
    "                start_time = float(line_split[0])\n",
    "                end_time = float(line_split[1])\n",
    "                key_no = int(line_split[2]) - 21\n",
    "                index_min = np.where(timing_arr >= start_time)[0] # finds the indexes of the timing array where the element is more than the stated start time\n",
    "                index_max = np.where(timing_arr > end_time - 0.01)[0] # finds the indexes of the timing array where the element is more than the stated end time\n",
    "                # print(type(index_min), type(index_max))\n",
    "                if index_min.size > 0 and index_max.size > 0:\n",
    "                    labels[index_min[0]:index_max[0], key_no] = 1 # finds the indexes where the key was pressed by finding the minimum start time and the minimum end time\n",
    "                else:\n",
    "                    print(f\"IndexError: Skipping iteration for {txtfile_path, start_time, end_time}\")\n",
    "\n",
    "        full_frames = no_frames//data_frame_size # splits the melspectrogram into chunks of frames where each chunk is of length data_frame_size\n",
    "        for idx in range(0, full_frames): \n",
    "            start_idx = idx\n",
    "            end_idx = idx + data_frame_size\n",
    "            temp_frame = melspecgram[start_idx:end_idx, :] # indexes the current frames\n",
    "            temp_labels = labels[start_idx:end_idx, :] # indexes the current labels\n",
    "            temp_labels = np.where(np.sum(temp_labels, axis=0) > 0, 1, 0) # condenses labels into (1, 88) array\n",
    "            # print(\"flag 7\")\n",
    "            newrow = {\n",
    "                    \"File Name\" : filelist[file][1][:-4], \n",
    "                    \"Subset Number\" : int(idx),\n",
    "                    \"Sampling Rate\": wavrate, \n",
    "                    \"Class\": filelist[file][1][:-4].split(\"_\")[1], \n",
    "                    \"Midi Labels\": temp_labels,\n",
    "                    \"Wav Array\" : temp_frame,\n",
    "                    \"Status\" : True\n",
    "                    }\n",
    "            df.loc[len(df)] = newrow # adds new row to df\n",
    "\n",
    "        start_idx = full_frames*data_frame_size #here we pad the leftovers and do the same\n",
    "        end_idx = no_frames\n",
    "        if start_idx != no_frames:\n",
    "            pad_size = data_frame_size - (end_idx - start_idx)\n",
    "            pad_wav = np.zeros((pad_size, 128))\n",
    "            pad_labels = np.zeros((pad_size, 88))\n",
    "\n",
    "            temp_frame = np.vstack((melspecgram[start_idx:end_idx, :], pad_wav))\n",
    "            temp_labels = np.vstack((labels[start_idx:end_idx, :], pad_labels))\n",
    "            temp_labels = np.where(np.sum(temp_labels, axis=0) > 0, 1, 0) # added to combine labels into 1 array\n",
    "            \n",
    "            newrow = {\n",
    "                    \"File Name\" : filelist[file][1][:-4], \n",
    "                    \"Subset Number\" : int(idx+1),\n",
    "                    \"Sampling Rate\": wavrate, \n",
    "                    \"Class\": filelist[file][1][:-4].split(\"_\")[1], \n",
    "                    \"Midi Labels\": temp_labels,\n",
    "                    \"Wav Array\" : temp_frame,\n",
    "                    \"Status\" : True\n",
    "                    }\n",
    "            df.loc[len(df)] = newrow\n",
    "            \n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"FileNotFoundError processing {filelist[file][0]}: {fnf_error}\")\n",
    "        newrow = {\n",
    "                \"File Name\" : filelist[file][1][:-4], \n",
    "                            \"Subset Number\" : int(idx/data_frame_size),\n",
    "                            \"Sampling Rate\": wavrate, \n",
    "                            \"Class\": filelist[file][1][:-4].split(\"_\")[1], \n",
    "                            \"Midi Labels\": np.nan,\n",
    "                            \"Wav Array\" : np.nan,\n",
    "                            \"Status\" : False\n",
    "                            }\n",
    "        \n",
    "        df.loc[len(df)] = newrow\n",
    "\n",
    "print(\"flag 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Wav Array'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(\"Vers6_ISOL_0_736_ENSTDKAM.pkl\")\n",
    "df.to_pickle(\"Maestro_1276_1914_43frames_to1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\melov\\OneDrive - Singapore Management University\\SMU General\\Y4S2\\IS460\\project\\dataprocessing\"\n",
    "source1 = \"_ENSTDkAm\"\n",
    "df = pd.read_pickle(path + r\"\\Vers6_ENSTDKAM_2205frames_to1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_songs(df, source, test_size, seed):\n",
    "    \"\"\"Splits files so that the classes are balanced\"\"\"\n",
    "    filename_df = df.groupby(['File Name'])[['Class']].max().reset_index()\n",
    "    filename_df['File Name'] = filename_df['File Name'].apply(lambda x: \"_\".join(x.split(\"_\")[:-1])).unique()\n",
    "    filename_df['Class'] = filename_df['Class'].apply(lambda x: x.split(\"-\")[0])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(filename_df[['File Name']], filename_df['Class'], stratify=filename_df['Class'], test_size=test_size, random_state=seed)\n",
    "    \n",
    "    source_trainfiles = list(map(lambda x: x+source, list(X_train['File Name'])))\n",
    "    source_testfiles = list(map(lambda x: x+source, list(X_test['File Name'])))\n",
    "\n",
    "    train = df[df['File Name'].isin(source_trainfiles)]\n",
    "    test = df[df['File Name'].isin(source_testfiles)]\n",
    "\n",
    "    print(df['File Name'].unique().shape, train['File Name'].unique().shape, test['File Name'].unique().shape)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3735,) (2988,) (747,)\n"
     ]
    }
   ],
   "source": [
    "train, test = split_songs(df=df, source=source1, test_size=0.2, seed= 1)\n",
    "train.to_pickle(\"ENSTDKAM_ver6_2205frame_to1_train.pkl\")\n",
    "test.to_pickle(\"ENSTDKAM_ver6_2205frame_to1_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
